{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objs as go\n",
    "pio.renderers.default='notebook'\n",
    "sns.set()\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.nn.functional import conv1d\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "def generate_jump(p, n, s, Norm):\n",
    "    ### Generate Delta, the direction of the change point located at tau1 ###\n",
    "\n",
    "    Delta = 2*torch.bernoulli(torch.tensor(p*[1/2])).reshape(-1, 1) - 1\n",
    "\n",
    "    ### Sparsify Delta\n",
    "    sparse_loc = torch.bernoulli(torch.tensor(p*[1- s/p])).bool()\n",
    "    Delta[sparse_loc] = 0\n",
    "    return (Norm/Delta.norm()) * Delta\n",
    "\n",
    "def generate_wcs(p, n, s, Norm, r=None, taus = None, samples=1):\n",
    "    '''generates worst case shape of time series, that is with two change-points.'''\n",
    "    for sample in range(samples):\n",
    "        ### Choose the scale r randomly ###\n",
    "        r = int(torch.randint(1, n//2, size=(1,))) if not r else r\n",
    "\n",
    "        ### Choose the location of the first change point ###\n",
    "        if not taus:\n",
    "            t1 = torch.randint(1, n - r - 1, size=(1,)).item()\n",
    "            tau1, tau2 = (t1, t1+r)\n",
    "        else:\n",
    "            tau1, tau2 = taus\n",
    "        print(taus, tau1, tau2)\n",
    "        print(f'generated worst case signal with cp at positions {(tau1, tau2)}\\n')\n",
    "\n",
    "        Delta = generate_jump(p, n, s, Norm)\n",
    "        Theta = torch.zeros((samples,p,n))\n",
    "        print(tau1, tau2)\n",
    "        Theta[sample, :, tau1:tau2] = Delta\n",
    "    return Theta\n",
    "\n",
    "def generate_K(p, n, s, Norm, K, samples=1):\n",
    "    Theta = torch.zeros(size=(samples,p,n)) #samples is for faster monte carlo\n",
    "    change_points = torch.randperm(n)[:K]\n",
    "    for tau in change_points:\n",
    "        for sample in range(samples):\n",
    "            Theta_single_cp = torch.zeros_like(Theta)\n",
    "            Theta_single_cp[sample, :, tau:] = generate_jump(p, n, s, Norm)\n",
    "            Theta.add_(Theta_single_cp)\n",
    "    return Theta\n",
    "\n",
    "\n",
    "def ending(r):\n",
    "    return (None if r==1 else -r+1)\n",
    "\n",
    "def logs_0(p, n, r, delta):\n",
    "    return np.maximum(int(np.log2(np.log2(n/(r*delta)))), 1)\n",
    "def logs_m(p, n, r, delta):\n",
    "    gamma_r = np.log2(n/(r*delta))\n",
    "    logsm = np.maximum(int(np.log2(np.sqrt(p*gamma_r)/(np.maximum(1, np.log2(p) - gamma_r)))), 1)\n",
    "    return np.minimum(logsm, int(np.log2(p)))\n",
    "\n",
    "def generate_grid(p, n, delta= 0.05):\n",
    "#CompleteGrid = list(range(n//2))\n",
    "    SemiDyadicGrid = [2**i for i in range(int(np.log2(n)))]\n",
    "    Grid = {}\n",
    "    for r in SemiDyadicGrid:\n",
    "        Grid[r] = [2**i - 1 for i in range(logs_m(p, n, r, delta) + 1)]\n",
    "        if 2**logs_m(p, n, r, delta) != p:\n",
    "            Grid[r].append(p - 1)\n",
    "    return Grid\n",
    "def compute_cusums(Ys, r):\n",
    "    samples, p, n = Ys.shape\n",
    "    Weights = torch.zeros((1, 1, r)) + 1\n",
    "    Convolutions = conv1d(Ys.reshape(samples*p, 1, n), Weights).reshape(samples, p, -1)\n",
    "    ConvolutionsFilled = torch.zeros_like(Ys)\n",
    "    end = ending(r)\n",
    "    ConvolutionsFilled[:, :, :end] = Convolutions\n",
    "    Convolutions = ConvolutionsFilled\n",
    "    #Cusums = CusumsFilled\n",
    "    Cusums = torch.zeros_like(Convolutions)\n",
    "    Cusums[:, :, r:end] = ((Convolutions[:, :, r:end] - Convolutions[:, :, :-2*r + 1])\n",
    "                            /np.sqrt(2*r))\n",
    "    return Cusums\n",
    "def compute_statistics_r(Y, r, Grid):\n",
    "    Cusums = compute_cusums(Y, r)\n",
    "    CusumsSquared = (Cusums**2).sort(dim=1, descending=True)[0] #sort along dimension R^p\n",
    "    PartialNorms = CusumsSquared.cumsum(dim=1)\n",
    "    Stats = PartialNorms[:, Grid[r], :]\n",
    "    return Stats\n",
    "def compute_statistics(Y, Grid, showbar=True):\n",
    "    Stats = {}\n",
    "    for r in Grid:\n",
    "        if showbar:\n",
    "            print(f'computing stats for r = {r}         ', end = '\\r')\n",
    "        Stats[r] = compute_statistics_r(Y, r, Grid)\n",
    "    return Stats\n",
    "    \n",
    "def compute_thresholds_r(Grid, p, n, r, delta=0.05, batch=50, samples=100):\n",
    "    Thresholds_r_batches = []\n",
    "    for i in range(samples//batch):\n",
    "        print(f\"r = {r} ; doing batch {i + 1}/{samples//batch}     \", end='\\r')\n",
    "        Noise = torch.randn((batch, p, n))\n",
    "        Stats_r = compute_statistics_r(Noise, r, Grid)\n",
    "        Expects_r = Stats_r[:, :, r:ending(r)].mean(dim=(0,2))\n",
    "        delta_rs = delta/(2*len(Grid)*len(Grid[r]))\n",
    "        Thresholds_r_batches.append(Stats_r[:,:,r:ending(r)].max(dim=2)[0])\n",
    "    Thresholds_concat = torch.concat(Thresholds_r_batches)\n",
    "    Thresholds_r = Thresholds_concat.quantile(1-delta_rs,dim=0)\n",
    "    Thresholds_r[-1] = Thresholds_concat[:, -1].quantile(1-delta/2, dim=0)\n",
    "    return Thresholds_r, Expects_r\n",
    "def compute_thresholds(Grid, p, n, delta=0.05, batch=50, samples=100):\n",
    "    Thresholds = {}\n",
    "    Expects = {}\n",
    "    for r in Grid:\n",
    "        Thresholds[r], Expects[r] = compute_thresholds_r(Grid, p, n, r, delta=delta, batch=batch, samples=samples)\n",
    "    return Thresholds, Expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiCP:\n",
    "    def __init__(self, p, n, delta=0.05, constants=None, samples=100, batch=20):\n",
    "        self.Grid = generate_grid(p, n)\n",
    "        if constants is None:  # We compute the grid of constants with montecarlo\n",
    "            # Noise = torch.randn((samples, p, n))\n",
    "            self.Thresholds = compute_thresholds(\n",
    "                self.Grid, p, n, delta=delta, samples=samples, batch=batch\n",
    "            )[0]\n",
    "        elif len(constants) == 3:\n",
    "            self.Thresholds = {}\n",
    "            for r in self.Grid:\n",
    "                for logs in range(len(self.Grid)):\n",
    "                    verysparse = (\n",
    "                        torch.Tensor(\n",
    "                            logs_0(p, n, r, delta) * [np.log2(n / (r * delta))]\n",
    "                        )\n",
    "                        * constants[0]\n",
    "                    )\n",
    "                    s = torch.Tensor(self.Grid[r][logs_0(p, n, r, delta) : -1])\n",
    "                    sparse = s * np.log2(2 * p / s) * constants[1] + s\n",
    "                    dense = (\n",
    "                        torch.Tensor([np.sqrt(p * np.log2(n / (r * delta)))])\n",
    "                        * constants[2]\n",
    "                        + p\n",
    "                    )\n",
    "                    self.Thresholds[r] = torch.concat((verysparse, sparse, dense))\n",
    "                    if len(self.Thresholds[r]) != len(self.Grid[r]):\n",
    "                        print(len(self.Thresholds[r]), len(self.Grid[r]))\n",
    "\n",
    "    def process(self, Y):\n",
    "        _, p, n = Y.shape\n",
    "        Stats = compute_statistics(Y, self.Grid)\n",
    "        S_left, S_right = [], []\n",
    "        S = {}\n",
    "        for r in self.Grid:\n",
    "            S[r] = []\n",
    "            S_left_r, S_right_r = [], []\n",
    "            right = -1\n",
    "            for l in range(r, n - r):\n",
    "                if not torch.any(\n",
    "                    (\n",
    "                        (torch.Tensor(S_right) >= l - r + 1).bool()\n",
    "                        & (torch.Tensor(S_right) <= l + r - 1).bool()\n",
    "                    )\n",
    "                    | (\n",
    "                        (torch.Tensor(S_left) >= l - r + 1).bool()\n",
    "                        & (torch.Tensor(S_left) <= l + r - 1).bool()\n",
    "                    )\n",
    "                ):\n",
    "                    Decision = Stats[r][0, :, l] / self.Thresholds[r]\n",
    "                    if torch.max(Decision) > 1:\n",
    "                        logsparsity = next((i for i, v in enumerate(Decision > 1) if v))\n",
    "                        if logsparsity == len(self.Grid[r])-1:\n",
    "                            sparsity = p\n",
    "                        else:\n",
    "                            sparsity = 2**logsparsity\n",
    "                        if l - r + 1 > right:\n",
    "                            if right != -1:\n",
    "                                S_left_r.append(left)\n",
    "                                S_right_r.append(right)\n",
    "                                S[r].append((left, right, sparsity))\n",
    "                            left = l - r + 1\n",
    "                        right = l + r - 1\n",
    "            if right != -1:  # add the last change-point detected\n",
    "                S_left_r.append(left)\n",
    "                S_right_r.append(right)\n",
    "                S[r].append((left, right, sparsity))\n",
    "            S_left.extend(S_left_r)\n",
    "            S_right.extend(S_right_r)\n",
    "        self.left = S_left\n",
    "        self.right = S_right\n",
    "        self.S = S\n",
    "        self.Stats = Stats\n",
    "\n",
    "        self.tau = []\n",
    "        self.scales = []\n",
    "        self.sparsities = []\n",
    "        for r in S:\n",
    "            for (left, right, s) in S[r]:\n",
    "                self.tau.append((left + right) // 2)\n",
    "                self.scales.append(r)\n",
    "                self.sparsities.append(s)\n",
    "        if self.tau:\n",
    "            self.tau, self.scales, self.sparsities = zip(\n",
    "                *sorted(zip(self.tau, self.scales, self.sparsities))\n",
    "            )\n",
    "        else:\n",
    "            self.tau, self.scales, self.sparsities = ((), (), ())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.manual_seed(1)\n",
    "p, n, s, samples = 100, 100, 100, 100\n",
    "r = 30\n",
    "tau1 = 30\n",
    "Signals = generate_wcs(p, n, s, r=r, Norm=10, taus=(tau1, tau1+r))\n",
    "Noise = torch.randn((samples, p, n))\n",
    "Ys = Signals + Noise\n",
    "mcp = MultiCP(p=p, n=n, samples=samples, delta=0.05)\n",
    "mcp.process(Ys)\n",
    "print('change-points for each scale r :\\n', mcp.S)\n",
    "\n",
    "Y = Ys[0]\n",
    "Signal = Signals[0]\n",
    "i = 0\n",
    "fig = go.Figure()\n",
    "x = list(range(n))\n",
    "fig.add_trace(go.Scatter(x=x, y=Y[i, :], name=r'$Y$', mode='markers'))\n",
    "fig.add_trace(go.Scatter(x=x, y=Signals[i, :], name=r'$\\Theta$', mode='markers'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(mcp.Grid.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp.tau, mcp.scales, mcp.sparsities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp.Stats[1][:,:,57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('em')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2df3c58bc0844e5a42d27e76da2fb645b9af260e81db40b52b0ed257377a2753"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
