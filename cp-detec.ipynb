{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='notebook_connected'\n",
    "sns.set()\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.nn.functional import conv1d\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_jump(p, n, s, Norm):\n",
    "    ### Generate Delta, the direction of the change point located at tau1 ###\n",
    "\n",
    "    Delta = 2*torch.bernoulli(torch.tensor(p*[1/2])).reshape(-1, 1) - 1\n",
    "\n",
    "    ### Sparsify Delta\n",
    "    sparse_loc = torch.bernoulli(torch.tensor(p*[1- s/p])).bool()\n",
    "    Delta[sparse_loc] = 0\n",
    "    return (Norm/Delta.norm()) * Delta\n",
    "\n",
    "def generate_wcs(p, n, s, Norm, r=None):\n",
    "    '''generates worst case shape of time series, that is with two change-points.'''\n",
    "    ### Choose the scale r randomly ###\n",
    "    r = int(torch.randint(1, n//2, size=(1,))) if r is None else r\n",
    "\n",
    "    ### Choose the location of the first change point ###\n",
    "    tau1 = torch.randint(0, n - r, size=(1,))\n",
    "    tau2 = tau1 + r\n",
    "\n",
    "    Delta = generate_jump(p, n, s, Norm)\n",
    "    Theta = torch.zeros((p,n))\n",
    "    Theta[:, tau1:tau2] = Delta\n",
    "    return Theta\n",
    "\n",
    "def generate_K(p, n, s, Norm, K, samples=1):\n",
    "    Theta = torch.zeros(size=(samples,p,n)) #samples is for faster monte carlo\n",
    "    change_points = torch.randperm(n)[:K]\n",
    "    for tau in change_points:\n",
    "        for sample in range(samples):\n",
    "            Theta_single_cp = torch.zeros_like(Theta)\n",
    "            Theta_single_cp[sample, :, tau:] = generate_jump(p, n, s, Norm)\n",
    "            Theta.add_(Theta_single_cp)\n",
    "    return Theta\n",
    "\n",
    "\n",
    "def ending(r):\n",
    "    return (None if r==1 else -r+1)\n",
    "\n",
    "def logs_0(p, n, r, delta):\n",
    "    return np.maximum(int(np.log2(np.log2(n/(r*delta)))), 1)\n",
    "def logs_m(p, n, r, delta):\n",
    "    gamma_r = np.log2(n/(r*delta))\n",
    "    logsm = np.maximum(int(np.log2(np.sqrt(p*gamma_r)/(np.maximum(1, np.log2(p) - gamma_r)))), 1)\n",
    "    return np.minimum(logsm, int(np.log2(p)))\n",
    "\n",
    "def generate_grid(p, n, delta= 0.05):\n",
    "#CompleteGrid = list(range(n//2))\n",
    "    SemiDyadicGrid = [2**i for i in range(int(np.log2(n)))]\n",
    "    Grid = {}\n",
    "    for r in SemiDyadicGrid:\n",
    "        Grid[r] = [2**i - 1 for i in range(logs_m(p, n, r, delta) + 1)]\n",
    "        if 2**logs_m(p, n, r, delta) != p:\n",
    "            Grid[r].append(p - 1)\n",
    "    return Grid\n",
    "def compute_cusums(Ys, r):\n",
    "    samples, p, n = Ys.shape\n",
    "    Weights = torch.zeros((1, 1, r)) + 1\n",
    "    Convolutions = conv1d(Ys.reshape(samples*p, 1, n), Weights).reshape(samples, p, -1)\n",
    "    ConvolutionsFilled = torch.zeros_like(Ys)\n",
    "    end = ending(r)\n",
    "    ConvolutionsFilled[:, :, :end] = Convolutions\n",
    "    Convolutions = ConvolutionsFilled\n",
    "    #Cusums = CusumsFilled\n",
    "    Cusums = torch.zeros_like(Convolutions)\n",
    "    Cusums[:, :, r:end] = ((Convolutions[:, :, r:end] - Convolutions[:, :, :-2*r + 1])\n",
    "                            /np.sqrt(2*r))\n",
    "    return Cusums\n",
    "def compute_statistics_r(Y, r, Grid):\n",
    "    Cusums = compute_cusums(Y, r)\n",
    "    CusumsSquared = (Cusums**2).sort(dim=1, descending=True)[0] #sort along dimension R^p\n",
    "    PartialNorms = CusumsSquared.cumsum(dim=1)\n",
    "    Stats = PartialNorms[:, Grid[r], :]\n",
    "    return Stats\n",
    "def compute_statistics(Y, Grid, showbar=True):\n",
    "    Stats = {}\n",
    "    for r in Grid:\n",
    "        if showbar:\n",
    "            print(f'computing stats for r = {r}         ', end = '\\r')\n",
    "        Stats[r] = compute_statistics_r(Y, r, Grid)\n",
    "    return Stats\n",
    "    \n",
    "def compute_thresholds_r(Grid, r, Stats_r, delta=0.05):\n",
    "    Expects_r = Stats_r[:, :, r:ending(r)].mean(dim=(0,2))\n",
    "    delta_rs = delta/(len(Grid)*len(Grid[r]))\n",
    "    Thresholds_r = Stats_r[:,:,r:ending(r)].max(dim=2)[0].quantile(1-delta_rs, dim=0)\n",
    "    return Thresholds_r, Expects_r\n",
    "def compute_thresholds(Grid, Stats, delta=0.05, showbar=True):\n",
    "    Thresholds = {}\n",
    "    Expects = {}\n",
    "    for r in Grid:\n",
    "        if showbar:\n",
    "            print(f'computing thresholds for r = {r}         ', end = '\\r')\n",
    "        Thresholds[r], Expects[r] = compute_thresholds_r(Grid, r, Stats[r], delta=delta)\n",
    "    return Thresholds, Expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log2(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "p, n, s, samples = 100, 100, 50, 100\n",
    "Signals = generate_K(p, n, s, Norm=1, K=10, samples=samples)\n",
    "Noise = torch.randn((samples, p, n))\n",
    "Ys = Signals + Noise\n",
    "Y = Ys[0]\n",
    "Signal = Signals[0]\n",
    "i = 4\n",
    "px.scatter({'data' : Y[i, :], 'signal' : Signal[i, :]} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cusums = compute_cusums(Signals, 5)\n",
    "A = compute_cusums(Noise, 5)[:,:,5:ending(5)]\n",
    "print('moyenne des cusums sur du bruit : ', (A**2).mean())\n",
    "px.line({'signal' : Signals[0, 12, :], 'cusums' : Cusums[0, 12, :]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, n, samples = 10000, 10, 100\n",
    "Noise = torch.randn((samples, p, n))\n",
    "Grid = generate_grid(p, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stats = compute_statistics(Noise, Grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_thresholds(Grid, Stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_constants_lists(\n",
    "    pmax, nmax, sigma=1, samples=30, delta=0.1, quantile=0.7, pmin=1, nmin=1\n",
    "):\n",
    "    C_dict = {}\n",
    "    Cdense_list = []\n",
    "    Csparse_list = []\n",
    "    Cverysparse_list = []\n",
    "    for p in [2**i for i in range(int(np.log2(pmin)), int(np.log2(pmax)) + 1)]:\n",
    "        C_dict[p] = {}\n",
    "        for n in [2**i for i in range(int(np.log2(nmin)), int(np.log2(nmax)) + 1)]:\n",
    "            C_dict[p][n] = {}\n",
    "            Noise = torch.randn((samples, p, n))\n",
    "            Grid = generate_grid(p, n)\n",
    "            for r in Grid:\n",
    "                print(f\"p = {p} ; n = {n} ;  r = {r}         \", end=\"\\r\")\n",
    "                Stats_r = compute_statistics_r(Noise, r, Grid)\n",
    "                Thresholds_r, Expects_r = compute_thresholds_r(Grid, r, Stats_r)\n",
    "                UB_verysparse = np.log2(n / (r * delta))\n",
    "                s = torch.Tensor(Grid[r])\n",
    "                UB_sparse = s * np.log2(p / s)\n",
    "                UB_dense = np.sqrt(p * np.log2(n / (r * delta)))\n",
    "                C_dict[p][n][r] = Thresholds_r - Expects_r\n",
    "                print(len(C_dict[p][n][r]))\n",
    "                Cverysparse_list.extend(\n",
    "                    C_dict[p][n][r][: logs_0(p, n, r, delta)] / UB_verysparse\n",
    "                )\n",
    "                Csparse_list.extend(\n",
    "                    (C_dict[p][n][r] / UB_sparse)[logs_0(p, n, r, delta): -1]\n",
    "                )\n",
    "                Cdense_list.append(C_dict[p][n][r][-1] / UB_dense)\n",
    "    return tuple(map(torch.Tensor, (Cverysparse_list, Csparse_list, Cdense_list)))\n",
    "\n",
    "\n",
    "def estimate_constants(constants_lists):\n",
    "    def f(C_list):\n",
    "        return C_list.sort(descending=True)[0][\n",
    "            len(C_list) // 5\n",
    "        ].mean()  # mean of the 20% highest const\n",
    "\n",
    "    return tuple(map(f, constants_lists))\n",
    "\n",
    "\n",
    "constants_lists = estimate_constants_lists(\n",
    "    pmax=1000, nmax=1000, pmin=999, nmin=999, samples=100, delta=0.3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_constants(constants_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimate_constants(constants_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_constants(constants_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cvsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor(Cdense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(27, dtype=float).reshape(3,3,3)\n",
    "a.max(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn((10, 3))\n",
    "print(torch.quantile(A, 0.5, dim=0, interpolation='higher'))\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CallibrateThresholds(p, n, Grid, samples=100, delta=0.99):\n",
    "    delta_r = delta/len(Grid) #This callibration is valid only for semi complete grid\n",
    "    thresholds = {}\n",
    "    for r in Grid:\n",
    "        Noise = torch.randn((samples, p, n))\n",
    "        Cusums = compute_cusums(Noise, r)\n",
    "        torch.quantile(a, 0.6, interpolation='higher')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('em')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2df3c58bc0844e5a42d27e76da2fb645b9af260e81db40b52b0ed257377a2753"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
